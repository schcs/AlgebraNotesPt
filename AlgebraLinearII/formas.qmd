--- 
title: "Formas $k$-lineares e o determinante de operadores"
number-sections: true
lang: pt-BR
--- 

## Aplicações $k$-lineares alternadas


:::{#def-}
Seja $f:V^k\to W$ uma aplicação $k$-linear. A aplicação $f$ é dita simétrica se
\begin{align*}
&f(v_1,\ldots,v_{i-1},v_i,v_{i+1},\ldots,v_{j-1},v_j,v_{j+1},\ldots,v_n)\\&=f(v_1,\ldots,v_{i-1},v_j,v_{i+1},\ldots,v_{j-1},v_i,v_{j+1},\ldots,v_n)
\end{align*}
para todo $i,j\in\{1,\ldots,k\}$ e $v_m\in V$.
A aplicação $f$ é dita alternada se
$$
f(v_1,\ldots,v_n)=0
$$
sempre que $v_i\in V$ e $v_i=v_j$ com algum $i\neq j$. Os espaços de aplicações $k$-lineares simétricas e alternadas $V^k\to W$ estão denotados por  $S^k(V,W)$ e $A^k(V,W)$, respetivamente. Escrevemos também $S^k(V)=S^k(V,\F)$ e $A^k(V,\F)=A^k(V)$.
:::


:::{#exm-klin-sym-alter}
O produto interno $\langle\cdot,\cdot\rangle$ em $\R^n$ é uma forma simétrica bilinear. 
O determinante no @exm-klin de uma matriz pode ser visto como uma aplicação $n$-linear $d:(\F^n)^n\to\F$ é alternada.
:::


:::{#lem-alter}
Seja $f:V^k\times W$ uma aplicação $k$-linear alternada. As seguintes afirmações são válidas:


 1. $f(\ldots,v_i,\ldots,v_j,\ldots)=-f(\ldots,v_j,\ldots,v_i,\ldots)$
 2. Se $v_1,\ldots,v_k$ são linearmente dependentes, então $f(v_1,\ldots,v_k)=0$.
:::


:::{.proof}
1. Calculamos que
\begin{align*}
0&=f(\ldots,v_i+v_j,\ldots,v_i+v_j,\ldots)\\&=f(\ldots,v_i,\ldots,v_i,\ldots)+f(\ldots,v_i,\ldots,v_j,\ldots)\\&+f(\ldots,v_j,\ldots,v_i,\ldots)+f(\ldots,v_j,\ldots,v_j,\ldots)\\&=f(\ldots,v_i,\ldots,v_j,\ldots)+f(\ldots,v_j,\ldots,v_i,\ldots).
\end{align*}

1. Se os $v_i$ são L.D., então algum $v_i$ é combinação linear dos demais vetores no sistema. Assuma que $v_1$ é combinação linear de $v_2,\ldots,v_k$. Ou seja,
$$
v_1=\alpha_2 v_2+\cdots+\alpha_k v_k.
$$
Então
\begin{align*}
&f(v_1,v_2,\ldots,v_k)\\&=
f(\alpha_2 v_2+\cdots+\alpha_k v_k,v_2,\ldots,v_k)\\&=
\alpha_2 f(v_2,v_2,\ldots,v_k)+\cdots+\alpha_k f(v_k,v_2,\ldots,v_k)=0.
\end{align*}
:::

## O sinal de uma permutação

Se $X$ é um conjunto, uma aplicação $\sigma:X\to X$ invertível (ou seja, sobrejetiva e injetiva) é chamada de <b>permutação</b> de $X$. A composição de permutações de $X$ é uma permutação de $X$. Uma transposição de $X$ é uma permutação que troca $i,j\in X$ distintos e deixa os demais elementos de $X$ fixados. Quando $X$ é finito, qualquer permutação de $X$ pode ser obtida como uma composição de transposições (qualquer configuração de um baralho pode ser atingida  trocando duas cartas e repetindo tais trocas). É um fato na teoria das permutações que se $\sigma:X\to X$ é uma permutação e
$$
\sigma=\sigma_1\circ\cdots\circ \sigma_m
$$
onde os $\sigma_i$ são transposições, então a paridade do número $m$ depende apenas da permuação $\sigma$. Se a paridade de $m$ é par, então a permutação $\sigma$ é <b>par</b>, caso contrário $\sigma$ é <b>ímpar</b>. Além disso, escrevemos
$$
(-1)^\sigma=\left\{\begin{array}{cc}
1 & \mbox{se $\sigma$ for par;}\\ -1 & \mbox{se $\sigma$ for ímpar.}\end{array}\right.
$$

:::{#exm-}
Considere a seguinte permutação $\sigma$ do conjunto $\{1,2,3,4\}$:
$$\left [
\begin{array}{cccc}
1 & 2 & 3 & 4\\
2 & 3 & 4 & 1 \end{array}\right].
$$
Se $i,j\in\{1,2,3,4\}$, então denotamos por $(i,j)$ a transposição que troca $i$ e $j$ e deixa os demais elementos fixados. Então pode verificar com conta simples que
$$
\sigma=(1,4)\circ (1,3)\circ(1,2)=(2,4)\circ(1,2)\circ (1,3)\circ(1,4)\circ(2,4).
$$
Ou seja, a mesma permutação $\sigma$ pode ser escrita como uma composição de $3$ transposições, mas também como uma composição de $5$ transposições. Portanto que $(-1)^\sigma=-1$.
:::


## Aplicações $k$-lineares alternadas

:::{#cor-alter-basis}
Seja $V$ um espaço vetorial de dimensão $n$ com base $B=\{b_1,\ldots,b_n\}$ e $f:V^k\to W$ uma aplicação $k$-linear alternada.


1. Se $v_1,\ldots,v_k\in V$ e $\sigma$ é uma permutação do conjunto $\{1,\ldots,k\}$, então
$$
f(v_{\sigma(1)},\ldots,v_{\sigma(k)})=(-1)^\sigma f(v_1,\ldots,v_k).
$$
2. $f$ está determinada pelos valores $f(b_{i_1},\ldots,b_{i_k})$ com $i_1<\cdots<i_k$.
:::


:::{.proof}
1. Se $\sigma$ é a composição de $m$ transposições, então a permutação $v_{\sigma(1)},\ldots,v_{\sigma(k)}$ de vetores pode ser  obtida da configuração original $v_1,\ldots,v_k$ aplicando as $k$ transposições, cada  uma depois a outra. Cada transposição multiplica o valor de $f$ por $-1$, logo depois de aplicar $m$ transposições, o valor original $f(v_1,\ldots,v_k)$ será multiplicado por $(-1)^m=(-1)^\sigma$.

2. Por @exm-bilin-mat, $f$ está determinado pelos valores $f(b_{i_1},\ldots,b_{i_k})$ com $i_j\in\{1,\ldots,n\}$. 
   Pela definição da aplicação $k$-linear alternada, se $i_j=i_l$ com $j\neq l$, então $f(b_{i_1},\ldots,b_{i_k})=0$. Logo pode-se dizer que $f$ está determinado pelos valores $f(b_{i_1},\ldots,b_{i_k})$ onde os $i_j$ são distintos. Existe uma única permutação $\sigma$ de $\{1,\ldots,k\}$ tal que $i_{\sigma(1)}< i_{\sigma(2)}< \cdots <i_{\sigma(k)}$. Pelo item 1., temos que
$$
(-1)^\sigma f(b_{i_1},\ldots,b_{i_k})=f(b_{i_{\sigma(1)}},\ldots,b_{i_{\sigma(k)}})
$$
:::

:::{#lem-basis-alter}
Seja $V$ um espaço vetorial com base $B=\{b_1,\ldots,b_n\}$ e seja $W$ um outro espaço sobre o mesmo corpo $\F$. 
Seja 
$$
B^{\{k\}}=\{(b_{i_1},\ldots,b_{i_k})\mid i_1<\cdots<i_k\}.
$$
Considerando 
$A^k(V,W)$ como um $\F$-espaço vetorial, temos que 
$$
A^k(V,W)\cong\mbox{Func}(B^{\{k\}},W).
$$
:::
:::{.proof}
Este lema nós não vamos provar, pois a prova é trabalhosa. A ideia é que uma função $f\in \mbox{Func}(B^{\{k\}},W)$ determina 
uma aplicação $k$-linear $B_f:V^k\to W$ por @cor-alter-basis. A parte não trivial é que esta aplicação é alternada. Depois o fato 
que a correspondência $f\mapsto B_f$ é um isomorfismo  é relativamente simples. 

Vamos provar este resultado no caso particular quando $k=n=\dim V$ e $W=\F$, pois é este caso que nós precisamos entender 
aqui. Considere então $A^n(V,\F)=A^n(V)$ e observe que 
$$
B^{\{n\}}=\{(b_1,\ldots,b_n)\}
$$
e em particlar $|B^{\{n\}}|=1$. Se $B:V^n\to \F$ é uma aplicação $n$-linear alternada, então @cor-alter-basis diz que 
$B$ está determinada pelo valor $B(b_1,\ldots,b_n)=\lambda_B\in \F$. Em outras palavras, a aplicação $A^n(V)\to \mbox{Func}(B^{\{n\}},\F)$ 
é injetiva e em particular $\dim A^n(V)\leq 1$. Então precisa verificar apenas que $\dim A^n(V)\neq 0$; ou seja, existe elemento 
não nulo em $A^n(V)$ mas isso segue do fato que o mapa determinante $d:A^n\to \F$ nos exemplos @exm-klin  e @exm-klin-sym-alter é 
um elemento não nulo de $A^n(V)$. 
:::

:::{#exr-dims-Ak}
Determine a dimensão de $A^k(V,W)$ onde $\dim V=m$ e $\dim W=n$. Demonstre em particular que 
$$
\dim A^k(V,W)=\binom mkn.
$$
:::


:::{#cor-AkV-dim1}
Seja $V$ um espaço vetorial sobre $\F$ de dimensão $n$ com base $\{b_1,\ldots,b_n\}$. Assuma que $\alpha\in\F$. Então existe uma única forma $n$-linear $f:V^n\to \F$ tal que $f(b_1,\ldots,b_n)=\alpha$. Consequentemente $\dim A^n(V)=1$.
:::


:::{#cor-}
Existe uma única forma $n$-linear $f:(\F^n)^n\to \F$ tal que $f(e_1,\ldots,e_n)=1$. Se $a_i=\sum_j a_{i,j} b_j\in V$, então
$$
f(a_1,\ldots,a_n)=\sum_{\sigma} (-1)^\sigma a_{1,\sigma(1)}\cdots a_{n,\sigma(n)}
$$
onde a soma está tomada sobre o conjunto das permutações do conjunto $\{1,\ldots,n\}$. Em outras palávras,
$$
f(a_1,\ldots,a_n)=\det A
$$
onde $A$ é a matriz com linhas $a_1,\ldots,a_n$.
:::


## O pullback e o determinante de operadores

Vamos definir o conceito de determinante para operadores $V\to V$ de espaços de dimensão finita independentemente das suas matrizes.

:::{#def-pullback}
Sejam $U$ e $V$ espaços vetoriai, seja $f:U\to V$ uma aplicação linear, e assuma que $k\geq 1$ fixado. Seja $T\in L^k(V)$. Defina
$f^*T\in L^k(U)$ como 
$$
f^*T\in L^k(U): (u_1,\ldots,u_k)\mapsto T(f(u_1),\ldots,f(u_k)).
$$
É fácil verificar que quando $T$ é uma forma $k$-linear, então $f^*T$ também é uma forma $k$-linear. Assim, obtemos uma aplicação 
$$
f^*:L^k(V)\to L^k(U).
$${#eq-def-fstar}
Esta aplicação chama-se o **pullback** de $f$. 
:::

:::{#lem-pullback}
Se $T$ é uma forma $k$-linear alternada, então $f^*T$ é também uma forma $k$-linear alternada. Portanto a restrição de $f^*$ definida na equação @eq-def-fstar resulta em uma aplicação linear
$$
f^*_A:A^k(V)\to A^k(U)
$$
para todo $k$.
:::

:::{.proof}
Exercício.
:::

Assuma agora que $f:V\to V$ onde $V$ é espaço de dimensão $n$ (finita). Pelo @cor-AkV-dim1, 
$A^n(V)$ é um espaço de dimensão $1$ e ele pode ser identificado com o corpo $\F$. Além disso, se $f:V\to V$, então o pullback 
$$
f^*_A:A^n(V)\to A^n(V)
$$
pode ser visto como  uma aplicação linear $\F\to \F$. As aplicações lineares $\F\to \F$ são dadas por multiplicação escalar com algum elemento de $\F$. Portanto $f_A^*$ também pode ser visto como multiplicação por um escalar $\delta\in\F$ que depende apenas de $f$. 

:::{#def-determinant-f}
O número $\delta$ no parágrafo anterior depende apenas da transformação $f:V\to V$ e chama-se o **determinante** de $f$ e será 
denotado por $\det f$. 
:::

:::{#exr-determinant-f}
Usando a @def-determinant-f, demonstre as propriedades comuns do determinante. 

1. Se $f,g: V\to V$, então $\det (f\circ g)=\det f\cdot \det g$.
2. $\det f$ coincide com o determinante da matriz de $f$ em uma base de $V$. 
3. $\det f=0$ se e somente se $f$ não é invertível.
:::


