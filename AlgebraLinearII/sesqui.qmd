--- 
title: "Formas sesquilineares"
number-sections: true
lang: pt-BR
--- 

:::{#def-}
Se $\F$ é um corpo, uma aplicação bijetiva $\sigma:\F\to \F$, $a\mapsto a^\sigma$, chama-se **automorfismo**, se


1. $(a+b)^\sigma=a^\sigma+b^\sigma$;
2. $(ab)^\sigma=a^\sigma b^\sigma$.
:::


:::{#exm-}
1. A bijeção $\mbox{id}_\F$ é automorfismo para todo corpo $\F$. Este automorfismo chama-se **automorfismo trivial**. Os corpos $\Q$, $\Z_p$ não têm automorfismos não triviais (consegue demonstrar?).

2. Se $\F=\C$, então $\sigma:\C\to \C$, $z^\sigma=\bar z$ (conjugado complexo) é um automorfismo de $\C$.

3. Se $\F$ é um corpo de caraterística $p$ (primo), então a aplicação $\varphi:a\mapsto a^p$ é injetiva e satisfaz as duas propriedades na definição de automorfismo. Para um corpo arbitrário, $\varphi$ não precisa ser sobrejetiva, mas se $\F$ é finito, então $\varphi$, sendo injetiva, será obrigatoriamente sobrejetiva e é um automorfismo. O automorfismo $\varphi$ de um corpo finito $\F$ é chamado de **automorfismo de Frobenius**.

4. É fácil provar que a composição de automorfismos é automorfismo. Em particular, se $\F$ é um corpo finito de caraterística $p$, então
$$
\varphi^k:\F\to \F, \quad a\mapsto a^{p^k}
$$
é um automorfismo de $\F$. Vocês vão aprender na disciplina Grupos e Corpos que todos os automorfismos de corpos finitos têm esta forma.

1. Se
$$
\F=\{a+b\sqrt 2\mid a,b \in \Q\},
$$
então $a+b\sqrt 2\mapsto a-b\sqrt 2$ é um automorfismo.

:::


:::{#def-sesquilinear}
Seja $V$ um $\F$-espaço vetorial e $\sigma:\F\to\F$ um automorfismo. Uma aplicação $B:V\times V\to \F$ chama-se **forma $\sigma$-sesquilinear** se

1. $B(\alpha u+\beta v,w)=\alpha B(u,w)+\beta B(v,w)$.
2. $B(u,\alpha v+\beta w)=\alpha^\sigma B(u,v)+ \beta^\sigma B(u,w)$.

Ou seja, uma forma sesquilinear, é uma forma de duas variáveis que é linear na primeira variável e $\sigma$-semilinear na segunda.
:::


:::{#def-}
Dada uma forma $B:V\times V\to \F$ sesquilinear, definimos os radicais da forma
$$
\mbox{Rad}_L(B)=\{v\in V\mid B(v,w)=0\mbox{ para todo }w\in V\}
$$
e
$$
\mbox{Rad}_R(B)=\{w\in V\mid B(v,w)=0\mbox{ para todo }v\in V\}.
$$
O $\mbox{Rad}_L(B)$ chama-se **radical à esquerda**, enquanto $\mbox{Rad}_R(B)$ chama-se **radical à direita**.
:::


:::{#def-}
Assuma que $B:V\times V\to \F$ é uma forma sesquilinear sobre um espaço $V$ de dimensão $n$, finita. Seja $X=\{b_1,\ldots,b_n\}$ uma base de $V$. Definimos a **matriz de Gram** de $B$ como a matriz $G_X(B)=(B(b_i,b_j))_{i,j}$.
:::


:::{#lem-}
Sejam $V$ e $B$ como na definição anterior, assuma que $u,v\in V$ e denote por $[u]_X$ e $[v]_X$ os vetores colunas das coordenadas de $u$ e $v$ na base $X$, respetivamente. Se $(\alpha_1,\ldots,\alpha_n)\in\F^n$, então denote
$$
(\alpha_1,\ldots,\alpha_n)^\sigma=(\alpha_1^\sigma,\ldots,\alpha_n^\sigma).
$$
Temos que
$$
B(u,v)=([u]_X)^t G_X(B) ([v]_X)^\sigma.
$$
:::


:::{.proof}
Exercício.
:::


:::{#exr-}
Demonstre que se $\dim V$ é finita, então $\dim \mbox{Rad}_L=\dim \mbox{Rad}_R$. (Dica: Use o Lema anterior para obter sistemas de equações lineares para caraterizar $\mbox{Rad}_L$ e $\mbox{Rad}_R$ e mostre que os espaços de soluções têm a mesma dimensão.)
:::


:::{#exr-}
Seja $A=(a_{i,j})\in M_{n\times n}(\F)$ e denote por $A^\sigma$ a matriz $(a_{i,j}^\sigma)$. Demonstre que
$$
(A+B)^\sigma =A^\sigma+B^\sigma\quad\mbox{e}\quad (AB)^\sigma=A^\sigma B^\sigma.
$$
:::


:::{#lem-}
Assuma que $V$ tem dimensão finita e sejam $X$ e $Y$ bases de $V$. Então
$$
G_Y(B)=([\mbox{id}]^Y_X)^t G_X(B) [\mbox{id}^Y_X]^\sigma
$$
onde $[\mbox{id}^Y_X]^\sigma$ denota a matriz que obtemos de $[\mbox{id}^Y_X]$ aplicando $\sigma$ em todas as suas entradas.
:::


:::{.proof}
Sejam $v,w\in V$. Vamos calcular que
\begin{align*}
&([v]_Y)^t([\mbox{id}]^Y_X)^t G_X(B) [\mbox{id}^Y_X]^\sigma ([w]_Y)^\sigma\\
&=([\mbox{id}]^Y_X [v]_Y)^tG_X(B)([\mbox{id}^Y_X][w]_Y)^\sigma\\
&=([v]_X)^tG_X(B)([w]_X)^\sigma =B(v,w).
\end{align*}
Isso implica que $G_Y(B)=([\mbox{id}]^Y_X)^t G_X(B) [\mbox{id}^Y_X]^\sigma$.
:::


:::{#def-}
Uma forma $\sigma$-sesquilinear $B$ chama-se **reflexiva**, se $B(u,v)=0$ implica que $B(v,u)=0$.  Se $B$ é uma forma refexiva, então $\mbox{Rad}_L(B)=\mbox{Rad}_R(B)$ e este espaço é chamado de **radical** de $B$ e será denotado por $\mbox{Rad}(B)$. A forma $B$ é dita **não degenerada** se $\mbox{Rad}(B)=0$.
:::


:::{#def-}
Seja $B$ uma forma $\sigma$-sesquilinear.

1. $B$ é chamada **$\sigma$-Hermitiana** se $B(u,v)=B(v,u)^\sigma$ para todo $u,v\in V$.
2. $B$ é chamada **simétrica** se $B(u,v)=B(v,u)$ para todo $u,v\in V$
3. $B$ é chamada **alternada** se $B(u,u)=0$ para todo $u\in V$.
:::


:::{#lem-}
As seguintes são verdadeiras para uma forma $\sigma$-sesquilinear não trivial:

1.  Se $B$ é $\sigma$-Hermitiana, então $\sigma^2=\mbox{id}_\F$.
2.  Se $B$ é alternada, então $B(u,v)=-B(v,u)$ para todo $u,v\in V$.
3.  Se $B$ é alternada, então $\sigma=\mbox{id}_\F$.
4.  Se $\mbox{car}(\F)\neq 2$, e $B(u,v)=-B(v,u)$ para todo $u,v\in V$, então $B$ é alternada.
5.  Se $B$ é simétrica, então $\sigma=\mbox{id}_\F$. 
:::


:::{.proof}
1. Seja $\alpha\in \F$ tal que $\alpha=B(u,v)$ (tais $u,v$ existem pois $B$ é não trivial). Então
$$
\alpha=B(u,v)=B(v,u)^\sigma=B(u,v)^{\sigma^2}=\alpha^{\sigma^2}.
$$
Logo $\alpha^{\sigma^2}=\alpha$ e $\sigma^2=\mbox{id}_\F$.

2. Com $u,v\in V$, calculemos que
\begin{align*}
0&=B(u+v,u+v)=B(u,u)+B(u,v)+B(v,u)+B(v,v)\\&=B(u,v)+B(v,u).
\end{align*}
Logo $B(u,v)=-B(v,u)$.

3. Escolhe $u,v\in V$ tal que $B(u,v)=-B(v,u)=1$ (é possível trocando $u$ por um múltiplo escalar) e seja $\alpha\in \F$. Agora
$$
\alpha^\sigma=B(u,\alpha v)=-B(\alpha v,u)=-\alpha B(v,u)=\alpha.
$$
Ou seja $\alpha^\sigma=\alpha$ para todo $\alpha\in\F$ e $\sigma=\mbox{id}_\F$.

4. Assuma que $B(u,v)=-B(v,u)$ para todo $u,v$. Então $B(u,u)=-B(u,u)$ ou seja $2B(u,u)=0$ para todo $u\in V$. Se a caraterística do corpo é diferente de $2$, isso implica que $B(u,u)=0$ para todo $u\in V$.
   
5. Seja $B$ simétrica e esolha $u,v\in V$ tal que $B(u,v)\neq 1$. Então temos que para $\alpha\in\F$ que 
   $$
   \alpha=B(\alpha u,v)=B(v,\alpha u)=\alpha^\sigma B(v,u)=\alpha^\sigma B(u,v)=\alpha^\sigma.
   $$
   Logo, $\alpha^\sigma=\alpha$ para todo $\alpha\in \F$ e $\sigma=\mbox{id}_\F$. 
:::


:::{#def-}
Uma forma $\sigma$-Hermitiana é chamada **simétrica** se $\sigma=\mbox{id}_\F$. Se $B$ é simétrica, então $B(u,v)=B(v,u)$ para todo $u,v\in V$.
:::


:::{#exr-}
Seja $B$ uma forma $\sigma$-Hermitiana (incluindo simétrica) ou alternada sobre $V$ de dimensão finita. Seja $G=G_X(B)$ a matriz de Gram de $B$ em uma base $X$ de $V$. Mostre que

1.  $B$ é simétrica se e somente se $G^t=G$;
2.  $B$ é alternada se e somente se $G^t=-G$;
3.  $B$ é $\sigma$-Hermitiana se e somente se $G^t=G^\sigma$.
:::


:::{#thm-}
(O Teorema de Birkhoff-von Neumann)
Seja $B$ uma forma $\sigma$-sesquilinear reflexiva com $\dim (V/\mbox{Rad}(B))\geq 2$. Então

1.  $B$ é alternada; ou
2.  $B$ é simétrica; ou
3.  $B$ é múltiplo escalar de uma forma $\sigma$-Hermitiana com $\sigma\neq \sigma^2=\mbox{id}_\F$
:::


:::{.proof}
Nós não demonstramos este teorema. A leitora interessada na demonstração pode consultar as notas de [Nick Gill](https://nickpgill.github.io/files/2014/06/Lecture13.pdf).
:::


:::{#def-}
Se $V$ é um espaço com forma sesquilinear reflexiva $B$, então $u,v\in V$ são ditos **ortogonais** se $B(u,v)=0$. Escrevemos neste caso que $u\perp v$.
:::


:::{#exm-}
Se $B$ é alternada e $v\in V$, então $v\perp v$.
:::


:::{#exr-}
Seja $\sigma:\F\to\F$ um automorfismo. Denote por $\mbox{Fix}(\F)=\{a\in\F\mid a^\sigma=a\}$. Mostre que $\mbox{Fix}(\sigma)$ é um corpo.
:::


:::{#def-}
Seja $B:V\times V\to \F$ uma forma $\sigma$-Hermitiana (incluindo formas simétricas). Defina $Q:V\to \F$ como $Q(v)=B(v,v)$. Então $Q$ é chamada de **forma quadrática** associada com $B$.
:::


:::{#lem-}
Usando a notação da definição anterior, as seguintes afirmações são válidas para todo $u,v\in V$ e $\alpha\in\F$:

1.   $Q(v)\in\mbox{Fix}(\sigma)$;
2.   $Q(\alpha v)=\alpha\alpha^\sigma Q(v)=\alpha^{\sigma+1}Q(v)$;
3.   se $B$ é simétrica, então $Q(\alpha v)=\alpha^2 Q(v)$;
4.   $Q(u+v)-Q(u)-Q(v)=B(u,v)+B(v,u)=B(u,v)+B(u,v)^\sigma$;
5.   se $u\perp v$, então $Q(u+v)=Q(u)+Q(v)$ (Teorema de Pitágoras);
6.   $Q(u+v)+Q(u-v)=2Q(u)+2Q(v)$ (Regra do Paralelogramo);
7.   se $B$ for simétrica, então $Q(u+v)-Q(u)-Q(v)=2B(u,v)$.

Em particular, se $B$ for simétrica e $\mbox{car}(\F)\neq 2$, então
$$
B(u,v)=\frac 12(Q(u+v)-Q(u)-Q(v))
$$
e $B$ está determinada por $Q$.
:::


:::{.proof}
Simples, só aplicar a definição de $Q$.
:::


:::{#def-}
Seja $V$ com forma $\sigma$-hermitiana $B$. Um vetor $v\in V$ é dito **isotrópico** se $Q(v)=B(v,v)=0$.
:::


:::{#exm-}
Se $V=\R^n$ ou $\C^n$ e $B$ é o produto interno usual, então $0$ é o único vetor isotrôpico.
:::


:::{#exr-}
Seja $V$ um espaço de dimensão maior ou igual a $2$ sobre $\C$ e seja $B$ uma forma simétrica em $V$. Mostre que $V$ possui um vetor não nulo isotrópico. Este exercício mostra que é mesmo necessário usar o conjugado complexo na segunda variável na definição do produto interno para $\C$-espaços. Usando formas simétricas, não é possível obter um produto interno que resulta em uma métrica.
:::


:::{#exr-}
Seja $B$ uma forma sesquilinear reflexiva sobre um espaço $V$ de dimensão finita. Assuma que $G$ é a matriz da forma em uma base de $V$. Mostre que $\dim \mbox{Rad}(V)=\dim V-\mbox{posto}(G)$. Em particular, $B$ é não degenerada se e somente se $G$ é invertível.
:::


:::{#def-}
Seja $V$ um espaço com forma sesquilinear reflexiva $B$ e $U\leq V$. Definimos o **espaço ortogonal** $U^\perp$ de $U$ como
$$
U^\perp=\{v\in V\mid B(v,u)=0\mbox{ para todo }u\in U\}.
$$
:::


:::{#lem-}
As seguintes afirmações são válidas para o espaço ortogonal em relação a uma forma $\sigma$-sesquilinear reflexiva:


1.  $U^\perp\leq V$;
2.  Se $U\leq W$, então $W^\perp\leq U^\perp$;
3.  $\mbox{Rad}(V)=V^\perp$ e $V^\perp\leq U^\perp$ para todo $U\leq V$;
4.  Se $B$ é não degenerada e $\dim V$ é finita, então $\dim U^\perp+\dim U=\dim V$.
:::


:::{.proof}
As afirmações 1., 2., 3. são simples. Vamos provar apenas 4. Assuma que $\dim V=n$, que $X=\{b_1,\ldots,b_n\}$ é uma base de $V$ tal que $\{b_1,\ldots,b_k\}$ é base de $U$, e seja $G=G_X(B)$ a matriz de $B$ na base $X$. Temos por resultado anterior que um vetor $v$ com $[v]_X=(\alpha_1,\ldots,\alpha_n)^t$ pertençe a $U^\perp$ se e somente se
$$
(\alpha_1,\ldots,\alpha_n)G [w]_B^\sigma =0\quad \mbox{para todo}\quad w\in U
$$
que vale se e somente se
$$
(\alpha_1,\ldots,\alpha_n)G [b_i]_B^\sigma =0\quad \mbox{para todo}\quad i\in\{1,\ldots,k\}.
$$
A equação anterior é equivalente ao sistema de equações
$$
(\alpha_1,\ldots,\alpha_n)G e_i =0\quad \mbox{para todo}\quad i\in\{1,\ldots,k\}
$$
onde $e_1,\ldots,e_n$ é a base canônica de $\F^n$. Mas o sistema anterior é um sistema linear homogêneo com incôgnitas $\alpha_1,\ldots,\alpha_n$ e a matriz desta sistema está formada pelas primeiras $k$ linhas de $G^t$. Como $B$ é não degenerada, $G^t$ tem posto $k$ e o espaço de soluções tem dimensão $n-k$.
:::

Na situação do item 4. do resultado anterior, se $U\cap U^\perp=0$, então $V=U\oplus U^\perp$ e $U^\perp$ é chamado de **complemento ortogonal** de $U$. Neste caso, escrevemos que $V=U\perp U^\perp$ para indicar que os dois espaços na decomposição são ortogonais.

:::{#exm-}
Considere $V=\C^2$ com a forma bilinear simétrica $B(v,w)=v_1w_1+v_2w_2$ para $v=(v_1,v_2)$ e $w=(w_1,w_2)$ pertencentes a $\C^2$. Observe que não aplicamos o conjugado complexo na segunda variável! Note que esta forma está não degenerada, pois na base canônica a sua matriz é a matriz identidade. Considere a base $\{(1,i),(1,-i)\}$ de $\C^2$. Nesta base, a matriz da forma é
$$
\begin{pmatrix} 0 & 2 \\ 2 & 0\end{pmatrix}
$$
Se $U=\langle (1,i)\rangle$, então $U^\perp =U$ e $\C^2\neq U\oplus U^\perp$. Ou seja, o espaço ortogonal $U^\perp$ não é complemento ortogonal de $U$.
:::

