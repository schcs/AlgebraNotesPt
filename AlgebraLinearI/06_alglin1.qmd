--- 
title: "A matriz de uma transformação linear e mudança de base"
number-sections: true
lang: pt-BR
--- 

## A matriz de uma transformação linear (caso geral) {#a-matriz-de-uma-transformação-linear-caso-geral .unnumbered}

A gente interpretou uma transformação linear $\R^m\to \R^n$ em termos de
uma matriz $n\times m$, usando as bases canônicas de $\R^m$ e $\R^n$. De
fato, exatamente a mesma coisa funciona com quaisquer espaços de
dimensão finita e quaisquer bases:

Sejam $V$ e $W$ espaços vetoriais com bases
$$B = \{\ul{b_1}, \ldots, \ul{b_m}\}$$
$$C = \{\ul{c_1}, \ldots, \ul{c_n}\}$$ respectivamente. Qualquer
vetor $\ul{w}$ de $W$ pode ser escrito unicamente como uma combinação
linear dos $\ul{c_i}$:
$$\ul{w} = \lambda_1 \ul{c_1} + \cdots + \lambda_n\ul{c_n}$$ com
$\lambda_i\in \R$. Logo, o vetor $$\begin{pmatrix}
\lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n
\end{pmatrix}$$ representa o vetor $\ul{w}$ com respeito à base $C$.
Diremos que o vetor $$\ul{w}_C = \begin{pmatrix}
\lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n
\end{pmatrix}$$ é o *vetor de coordenadas de $\ul{w}$ com respeito à
base (ordenada) $C$*. Observe que o mesmo vetor $\ul{w}$ vai ter
diferentes vetores de coordenadas com respeito a bases diferentes.

Lembre da demonstração do @cor-isom-Rn que o mapa $\ul{v}\mapsto v_B$ é um isomorfismo $V\to \R^m$ (@def-isom-vect) de espaços vetoriais.  

:::{#exr-mat-equal}
Suponha que $A$ a $B$ são matrizes $m\times n$ tal que 
$$
Av=B\ul{v}
$$
para todo $\ul{v}\in \R^n$ (vetor coluna). Demonstre que $A=B$.
:::

:::{#exm-}
O vetor $(2,3)$ de $\R^2$ tem vetor de coordenadas $\begin{pmatrix}
2 \\ 3
\end{pmatrix}$ com respeito à base canônica $\{(1,0)\,,\,(0,1)\}$, pois
$$(2,3) = 2(1,0) + 3(0,1).$$ Considere a base $C = \{(1,1)\,,\,(2,1)\}$
de $\R^2$. Temos $$4\cdot(1,1) - 1\cdot(2,1) = (2,3).$$ Então o vetor de
coordenadas de $(2,3)$ com respeito à base $C$ é $\begin{pmatrix}
4 \\ -1
\end{pmatrix}$.
:::

Uma transformação linear $T:V\to W$ é completamente determinada pelas
imagens dos vetores $\ul{b_j}$ em $W$. Cada $T(\ul{b_j)}$ é uma
combinação linear dos elementos de $C$, então escreve
$$T(\ul{b_j}) = a_{1j}\ul{c_1} + \cdots + a_{nj}\ul{c_n}.$$ Logo o vetor
de coordenadas de $T(\ul{b_j})$ com respeito à base $C$ é
$$T(\ul{b_j})_C = \begin{pmatrix}
a_{1j} \\ a_{2j} \\ \vdots \\ a_{nj}
\end{pmatrix}.$$ Obtemos assim a matriz $A$ cuja $j$-ésima coluna é
$T(\ul{b_j})_C$: $$A = \begin{pmatrix}
T(\ul{b_1})_C & T(\ul{b_2})_C & \cdots & T(\ul{b_m})_C
\end{pmatrix} = \begin{pmatrix}
a_{11} & \cdots & a_{1j} & \cdots & a_{1m} \\ a_{21} & \cdots & a_{2j} & \cdots & a_{2m} \\
\vdots & & \vdots & & \vdots \\
a_{n1} & \cdots & a_{nj} & \cdots & a_{nm} 
\end{pmatrix}.$$ A transformação linear $T$, escrita com respeito às
bases $B,C$, tem a forma $T_A$: O vetor de coordenadas do vetor
$\ul{b_j}$ com respeito à base $B$ é $$\begin{aligned}
\begin{pmatrix}
0 \\ \vdots \\ 1 \\ \vdots \\ 0
\end{pmatrix}\quad(j\hbox{-ésima linha}) 
\end{aligned}$$ Logo $$\begin{aligned}
T_A(\ul{b_j}) & = \begin{pmatrix}
a_{11} & \cdots & a_{1j} & \cdots & a_{1m} \\ a_{21} & \cdots & a_{2j} & \cdots & a_{2m} \\
\vdots & & \vdots & & \vdots \\
a_{n1} & \cdots & a_{nj} & \cdots & a_{nm} 
\end{pmatrix}\cdot \begin{pmatrix}
0 \\ \vdots \\ 1 \\ \vdots \\ 0
\end{pmatrix}\quad(j\hbox{-ésima linha}) \\
& = \begin{pmatrix}
a_{1j} \\ a_{2j} \\ \vdots \\ a_{nj}
\end{pmatrix} \\
& = T(\ul{b_j}).\qquad\qquad \checkmark
\end{aligned}$$

Uma notação pra matriz $A$ acima:

:::{#def-mat-tl}
Sejam $V,W$ espaços vetoriais de dimensão finita com bases ordenadas
$B = \{\ul{b_1}, \ldots, \ul{b_m}\},C = \{\ul{c_1}, \ldots, \ul{c_n}\}$
respetivamente. Seja $T:V\to W$ uma transformação linear. Denote por
$[T]_C^B$ a matriz $n\times m$ de $T$ com respeito às bases $B,C$. Isto
é, $[T]_B^C$ é a matriz cujas colunas são os vetores de coordenadas com
respeito à base $C$ dos vetores $T(\ul{b_j})$ ($j\in \{1,\ldots,m\}$):
$$[T]_C^B = \begin{pmatrix}
T(\ul{b_1})_C & T(\ul{b_2})_C & \cdots & T(\ul{b_m})_C
\end{pmatrix}.$$
:::


:::{#lem-mat-tl}
Usando a notação na @def-mat-tl, tem-se que 
$$
[T(\ul{v})]_C=[T]^B_C\cdot \ul{v}_B\quad \mbox{para todo $\ul{v}\in V$}.
$$
:::

:::{.proof}
Assuma que 
$$
\ul{v}=\sum_{i=1}^m \beta_i\ul{b_i}.
$$
Então 
\begin{align*}
[T(\ul{v})]_C&=\left[T\left(\sum_{i=1}^m \beta_i\ul{b_i}\right)\right]_C=
\left[\sum_{i=1}^m \beta_iT(\ul{b_i})\right]_C\\&=
\sum_{i=1}^m \beta_i[T(\ul{b_i})]_C=[T]_C^B\begin{pmatrix} \beta_1\\ \vdots \\\beta_n\end{pmatrix}=
[T]^B_Cv_B.
\end{align*}

As justificativas para as igualdades na conta anterior (em ordem de aparência):

- a expressão de $\ul{v}$ na primeira linha destacada;
- $T$ é linear;
- $\ul{v}\mapsto [\ul{v}]$ é linear;
- a $i$-ésima linha de $[T]^B_C$ é $[T(\ul{b_i})]_C$;
- a definição de $v_B$. 
:::


Observe que a matriz $[T]_C^B$ depende das escolhas das bases $B$ e $C$.
Com respeito a outras bases de $V,W$, a *mesma* transformação linear $T$
teria uma matriz *diferente*.

:::{#exm-}
Vamos considerar $V = W = \R^2$, mas com duas bases diferentes. Sejam
$B$ a base canônica $$\{\ul{b_1}\,,\,\ul{b_2}\} = \{(1,0)\,,\,(0,1)\}$$
e $C$ a base $$\{\ul{c_1}\,,\,\ul{c_2}\} = \{(1,1)\,,\,(2,1)\}.$$ A
transformação identidade $I$ de $\R^2$ manda o vetor $\ul{v}$ para
$\ul{v}$. Mas o vetor de coordenadas de $\ul{v}$ depende da base. Temos
que $$(1,0) = -(1,1) + (2,1)$$ e $$(0,1) = 2(1,1) - (2,1).$$ Logo, com
respeito à base $C$, os vetores $\ul{b_1}, \ul{b_2}$ têm vetores de
coordenadas $$(\ul{b_1})_C = \begin{pmatrix}
-1 \\ 1
\end{pmatrix}\quad,\quad(\ul{b_2})_C = \begin{pmatrix}
2 \\ -1
\end{pmatrix}.$$ Segue que a matriz $[I]_C^B$ da transformação
identidade com respeito às bases $B,C$ é $$[I]_C^B = \begin{pmatrix}
I(1,0)_C & I(0,1)_C
\end{pmatrix} = \begin{pmatrix}
-1 & 2 \\ 1 & -1
\end{pmatrix}.$$
:::

:::{#thm-}
Sejam $V$ e $W$ espaços vetoriais de dimensão finita com bases ordenadas
$B = \{\ul{b_1}\,,\ldots,\ul{b_m}\},C = \{\ul{c_1}\,,\ldots,\ul{c_n}\}$
respetivamente. A função $$\rho : \mathcal{L}(V,W) \to M_{n,m}(\R)$$
dada por $T\mapsto [T]_C^B$ é um isomorfismo de espaços vetoriais.
:::

:::{.proof}
Exercício. ◻
:::

:::{#thm-mat-comp}
Sejam $U,V,W$ espaços vetoriais de dimensão finita com bases $B,C,D$
respetivamente e sejam $$U\xrightarrow{S}V\xrightarrow{T}W$$
transformações lineares. Então $$[T]_D^C\cdot [S]_C^B = [TS]_D^B.$$
Informalmente: a composição de duas transformações lineares está dada
pela multiplicação das matrizes correspondentes.
:::

:::{.proof}
Temos pelo @lem-mat-tl que 
$$
[TS(\ul{u})]_D=[TS]^B_D\cdot \ul{u}_B\quad \mbox{para todo}\quad \ul{u}\in U.
$$
Por outro lado 
$$
[TS(\ul{u})]_D=[T(S(\ul{u}))]_D=[T]^C_D\cdot S(\ul{u})_C=[T]^C_D([S]^B_C\cdot \ul{u}_B)=([T]^C_D[S]^B_C)\cdot \ul{u}_B.
$$
Ora, usando o @exr-mat-equal, obtemos que 
$$
[TS]^B_D=[T]^C_D[S]^B_C.
$$
:::

## Mudança de base {#mudança-de-base .unnumbered}

Dependendo da situação, um espaço vetorial pode possuir uma base "mais
conveniente" para fazer cálculos. A base mais conveniente não tem que
ser uma base canônica. Então, seria útil entender como mudar de uma base
a uma outra num espaço vetorial.

Suponha que temos dois espaços vetoriais $V,W$ com dimensões $m,n$
respetivamente e $T:V\to W$ uma TL. Com respeito às bases $B,C$ de $V,W$
respetivamente, a matriz da transformação é $$[T]_C^B.$$ Agora suponha
que temos mais duas bases $B', C'$ de $V$ e $W$. Qual é a matriz de $T$
com respeito às bases novas $B',C'$? Para responder esta pergunta, usaremos 
o @thm-mat-comp. Considere a seguinte cadeia de transformações lineares:
$$
\begin{array}{ccccccc}
V & \overset{I_V}\longrightarrow & V & \overset{f}\longrightarrow & W & \overset{I_W}\longrightarrow & W\\ 
B' && B && C && C'
\end{array}
$$
Na primeira linha temos as transformações (em que $I_V, I_W$ são as TLs identidades de $V,W$), enquanto na segunda temos as bases dos espaços correspondentes. Note que $I_W\circ f\circ I_V=f$ e podemos usar o @thm-mat-comp duas vezes para obter que 
$$
\boxed{{[T]}_{C'}^{B'} = [I_W]_{C'}^{C}\cdot[T]_C^B\cdot[I_V]_{B}^{B'}}
$$
pois
\begin{align*}
  [I_W]_{C'}^{C}[T]_C^B[I_V]_{B}^{B'} & = [I_W]_{C'}^{C}[T\circ I_V]_{C}^{B'} \\
                 & = [I_W\circ T\circ I_V]_{C'}^{B'} \\
                 & = [T]_{C'}^{B'}.\qquad \checkmark
\end{align*}


:::{#def-}
Quando $B,C$ são bases finitas do espaço vetorial $V$, a matriz
$[I_V]_C^B$ se chama da *matriz de mudança de base de $B$ para $C$*.
:::

:::{#exm-}
Seja $T:\R^2 \to \R^3$ a transformação linear dada com respeito às bases
canônicas pela matriz $$A = \begin{pmatrix}
1 & 2 \\
0 & 4 \\
3 & 1
\end{pmatrix}.$$ Qual é a matriz de $T$ com respeito às bases
$B = \{(1,1)\,,\,(2,1)\}$ de $\R^2$ e
$C = \{(1,1,1)\,,\,(0,1,1)\,,\,(0,0,1)\}$ de $\R^3$?

R: Denote as bases canônicas de $\R^2, \R^3$ por $E,F$ respetivamente. A
questão nos deu a matriz $A = [T]_F^E$ e queremos calcular $[T]_C^B$.
Pela conversa acima, temos $$[T]_C^B = [I]_C^F[T]_F^E[I]_E^B,$$ então
temos que calcular $[I]_E^B$ e $[I]_C^F$.

-   Os vetores de coordenadas de $(1,1), (2,1)$ com respeito à base
    canônica $E$ são obviamente $$(1,1)_E = \begin{pmatrix}
      1 \\ 1
      \end{pmatrix}\quad,\quad (2,1)_E = \begin{pmatrix}
      2 \\ 1
      \end{pmatrix},$$ então $$[I]_E^B = \begin{pmatrix}
      (1,1)_E & (2,1)_E
      \end{pmatrix} = \begin{pmatrix}
      1 & 2 \\ 1 & 1
      \end{pmatrix}.$$

-   Temos \begin{aligned}
        (1,0,0) & = (1,1,1) - (0,1,1) \\
        (0,1,0) & = (0,1,1) - (0,0,1) \\
        (0,0,1) & = (0,0,1).
      
    \end{aligned} Então $$(1,0,0)_C = \begin{pmatrix}
      1 \\ -1 \\ 0 
      \end{pmatrix}\quad,\quad(0,1,0)_C = \begin{pmatrix}
      0 \\ 1 \\ -1 
      \end{pmatrix}\quad,\quad(0,0,1)_C = \begin{pmatrix}
      0 \\ 0 \\ 1 
      \end{pmatrix}$$ logo $$[I]_C^F = \begin{pmatrix}
      (1,0,0)_C & (0,1,0)_C & (0,0,1)_C
      \end{pmatrix} = \begin{pmatrix}
      1 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & -1 & 1
      \end{pmatrix}.$$

Agora é só fazer o cálculo: 
\begin{align*}
  [T]_C^B & = [I]_C^F\cdot[T]_F^E\cdot[I]_E^B \\
      & = \begin{pmatrix}
  1 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & -1 & 1
  \end{pmatrix}\cdot \begin{pmatrix}
1 & 2 \\
0 & 4 \\
3 & 1
\end{pmatrix}\cdot \begin{pmatrix}
  1 & 2 \\ 1 & 1
  \end{pmatrix} \\
  & = \begin{pmatrix}
  1 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & -1 & 1
  \end{pmatrix}\cdot \begin{pmatrix}
3 & 4 \\
4 & 4 \\
4 & 7
\end{pmatrix} \\
& = \ul{\ul{\begin{pmatrix}
3 & 4 \\
1 & 0 \\
0 & 3
\end{pmatrix}}}.
\end{align*}
:::

## Endomorfismos e semelhança {#endomorfismos-e-semelhança .unnumbered}

Seja $V$ um espaço vetorial de dimensão $n$, e sejam
$$B = \{\ul{b_1}\,,\,\ldots\,,\,\ul{b_n}\}\quad,\quad C = \{\ul{c_1}\,,\,\ldots\,,\,\ul{c_n}\}$$
duas bases de $V$. Seja $P$ a matriz $n\times n$ $$P = [I]_C^B,$$ a
matriz da transformação identidade de $V$ com respeito às bases $B,C$.
Considere também a matriz $[I]_B^C$. Temos
$$[I]_B^C\cdot [I]_C^B = [I\circ I]_C^C = [I]_B^B = \begin{pmatrix}1 & 0 & \cdots & 0 \\
0 & 1 &    & 0 \\
\vdots & & \ddots & \vdots \\
0 & 0 & \cdots & 1 
\end{pmatrix},$$ e similarmente $[I]_B^C\cdot [I]_B^C = I_n$. Ou seja, a
matriz $[I]_B^C$ é a matriz inversa de $[I]_C^B$:
$$P = [I]_C^B\quad,\quad P^{-1} = [I]_B^C.$$ 

:::{#exr-}
Prove uma versão mais geral deste resultado: Sejam $V, W$ espaços
vetoriais de dimensão $n$ e sejam $B,C$ bases de $V,W$ respetivamente.
Seja $T:V\to W$ uma TL.

1.  $T$ é um isomorfismo se, e somente se, a matriz $[T]_C^B$ é
    invertível.

2.  Caso $T$ for isomorfismo, então $$[T^{-1}]_B^C = ([T]_C^B)^{-1}.$$
:::

:::{#def-}
Seja $V$ um espaço vetorial. Um *endomorfismo* (ou *operador linear*) de
$V$ é uma transformação linear de $V$ a $V$.
:::

Quando mexermos com endomorfismos, quase sempre devemos pegar a mesma
base pro domínio e pro contradomínio, pois assim a gente pode compor os
endomorfismos por multiplicar as matrizes. Sejam $B,C$ duas bases do
espaço vetorial de dimensão finita $V$. Dado um endomorfismo $T:V\to V$,
suponha que sabemos a matriz $[T]_C^C$. Então, qual é a matriz
$[T]_B^B$?

Já sabemos que $$[T]_B^B = [I]_B^C\cdot [T]_C^C \cdot [I]_C^B.$$ Mas se
$[I]_C^B = P$, então $[I]_B^C = P^{-1}$, então
$$\boxed{[T]_B^B = P^{-1}\cdot [T]_C^C \cdot P}$$

:::{#def-}
Sejam $A,B$ duas matrizes $n\times n$. Diremos que $A, B$ são
*semelhantes* se existir uma matriz invertível $P$ tal que
$$A = P^{-1}BP.$$
:::

Acabamos de ver que quando $A,B$ são matrizes de um endomorfismo
$T: V\to V$ com respeito a bases diferentes, então $A,B$ são
semelhantes. Segue um exemplo onde "a base mais conveniente não é a base
canônica":

:::{#exm-}
O endomorfismo $T:\R^3\to \R^3$ tem matriz $$[T]_E^E = \begin{pmatrix}
4 & 0 & -2 \\ 2 & 1 & -1 \\ 4 & 0 & -2
\end{pmatrix}$$ com respeito à base canônica $E$ de $\R^3$. Calcule a
matriz de $T$ com respeito à base
$$B = \{\ul{b_1}\,,\,\ul{b_2}\,,\,\ul{b_3}\} = \{(0,-1,0)\,,\,(1,1,1)\,,\,(1,0,2)\}.$$

R: Vamos calcular $P = [I]_E^B$. Os vetores de coordenadas dos vetores
de $B$ com respeito à base canônica são:
$$(0,-1,0)_E = I(0,-1,0)_E = \begin{pmatrix}
0 \\ -1 \\ 0
\end{pmatrix}\,,\quad(1,1,1)_E = \begin{pmatrix}
1 \\ 1 \\ 1
\end{pmatrix}\,,\quad(1,0,2)_E = \begin{pmatrix}
1 \\ 0 \\ 2
\end{pmatrix}.$$ Logo a matriz $P$ é $$P = [I]_E^B = \begin{pmatrix}
0 & 1 & 1 \\ -1 & 1 & 0 \\ 0 & 1 & 2
\end{pmatrix}.$$ Usando as técnicas de GAAL, podemos calcular também que
$$[I]_B^E = P^{-1} = \begin{pmatrix}
0 & 1 & 1 \\ -1 & 1 & 0 \\ 0 & 1 & 2
\end{pmatrix}^{-1} = \begin{pmatrix}
2 & -1 & -1 \\ 2 & 0 & -1 \\ -1 & 0 & 1
\end{pmatrix}.$$ Agora 
\begin{align*}
  [T]_B^B & = [I]_B^E\cdot [T]_E^E \cdot [I]_E^B \\
      & = P^{-1}\cdot [T]_E^E \cdot P \\
      & = \begin{pmatrix}
2 & -1 & -1 \\ 2 & 0 & -1 \\ -1 & 0 & 1
\end{pmatrix}\cdot \begin{pmatrix}
4 & 0 & -2 \\ 2 & 1 & -1 \\ 4 & 0 & -2
\end{pmatrix} \cdot \begin{pmatrix}
0 & 1 & 1 \\ -1 & 1 & 0 \\ 0 & 1 & 2
\end{pmatrix} \\
     & = \begin{pmatrix}
2 & -1 & -1 \\ 4 & 0 & -2 \\ 0 & 0 & 0
\end{pmatrix} \cdot \begin{pmatrix}
0 & 1 & 1 \\ -1 & 1 & 0 \\ 0 & 1 & 2
\end{pmatrix} \\
     & = \ul{\ul{\begin{pmatrix}
1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 0
\end{pmatrix}}}.
\end{align*} 
Observe que com respeito à base canônica
$E = \{\ul{e_1}\,,\,\ul{e_2}\,,\,\ul{e_3}\}$, a TL $T$ é um pouco
bagunçada. Por exemplo,
$$T(\ul{e_1}) = 4\ul{e_1} + 2 \ul{e_2} + 4\ul{e_3}.$$ Mas com respeito à
base $B$, $T$ é muito fácil entender: 
\begin{align*}
  T(\ul{b_1}) & = \ul{b_1} \\
  T(\ul{b_2}) & = 2\ul{b_2} \\
  T(\ul{b_3}) & = \ul{0}.
\end{align*} A procura de uma base com respeito a qual uma
transformação linear é fácil de entender é um dos assuntos principais de
álgebra linear. Vamos falar mais sobre isso depois.
:::

## Invariantes de matrizes semelhantes {#invariantes-de-matrizes-semelhantes .unnumbered}

Nem quaisquer matrizes $n\times n$ $A,B$ são semelhantes. De fato,
matrizes semelhantes têm que ter muitas propriedades em comum. Vamos dar
três *invariantes* de matrizes semelhantes -- isto é, números associados a uma matriz quadrada que
são iguais sempre que as matrizes foram semelhantes.

:::{#def-}
Seja $A = (a_{ij})$ uma matriz $n\times n$. O *traço* de $A$ é a soma
das entradas da diagonal principal de $A$:
$$\tn{Tr}(A) = \sum_{i=1}^n a_{ii}.$$
:::

:::{#exm-}
Seja $$A = \begin{pmatrix}
4 & 2 & 3 \\ -1 & 5 & 3 \\ 1 & 1 & -2 
\end{pmatrix}.$$ Então
$$\tn{Tr}(A) = a_{11} + a_{22} + a_{33} = 4 + 5 + (-2) = \ul{\ul{7}}.$$
:::

Temos:

:::{#thm-}
$\tn{Tr}(AB) = \tn{Tr}(BA)$ para quaisquer matrizes $n\times n$
$$A = (a_{ij})\hbox{ e }B = (b_{ij}).$$
:::

:::{.proof}

$$(AB)_{ii} = \sum_{k=1}^n a_{ik}b_{ki}\quad,\quad (BA)_{ii} = \sum_{k=1}^n b_{ik}a_{ki}.$$
Então 
\begin{align*}
\tn{Tr}(AB) & = \sum_{i=1}^n (AB)_{ii} \\
      & = \sum_{i=1}^n \sum_{k=1}^n a_{ik}b_{ki} \\
      & = \sum_{i=1}^n \sum_{k=1}^n b_{ki}a_{ik} \\
      & = \sum_{k=1}^n \sum_{i=1}^n b_{ki}a_{ik} \\
      & = \sum_{k=1}^n (BA)_{kk} \\
      & = \tn{Tr}(BA).
\end{align*}
◻
:::

Logo

:::{#cor-}
Sejam $A,B$ matrizes semelhantes. Então
$$\boxed{\tn{Tr}(A) = \tn{Tr}(B).}$$
:::

:::{.proof}

\begin{align*}
  \tn{Tr}(A) & = \tn{Tr}((P^{-1}B)P) \\
      & = \tn{Tr}(P(P^{-1}B))\qquad(\hbox{pelo teorema}) \\
      & = \tn{Tr}(IB) \\
      & = \tn{Tr}(B).
\end{align*} ◻
:::

:::{#exm-}
Sejam $$A = \begin{pmatrix}
4 & 2 & 3 \\ -1 & 5 & 3 \\ 1 & 1 & -2 
\end{pmatrix}\quad,\quad P = \begin{pmatrix}
1 & 1 & 3 \\ 0 & 1 & 1 \\ 1 & -1 & 0 
\end{pmatrix}.$$ Então $P^{-1}AP = \begin{pmatrix}
-3 & 8 & 0 \\ -2 & 4 & -4 \\ 4 & -3 & 6 
\end{pmatrix}$, cujo traço é $$-3 + 4 + 6 = 7 = \tn{Tr}(A).$$
:::

Um outro número importante associado a uma matriz quadrada é o seu
determinante. Se lembra que o *determinante* de uma matriz $1\times 1$ é
$$\tn{Det}\begin{pmatrix}
a
\end{pmatrix} = a,$$ e de uma matriz $2\times 2$ é
$$\tn{Det}\begin{pmatrix}
a & b \\ c & d 
\end{pmatrix} = ad - bc.$$ O determinante de uma matriz $n\times n$
$A = (a_{ij})$ está dado recursivamente pela fórmula
$$\tn{Det}(A) = a_{11}\tn{Det}(\widetilde{A_{11}}) - a_{12}\tn{Det}(\widetilde{A_{12}}) + a_{13}\tn{Det}(\widetilde{A_{13}}) - \cdots + (-1)^{1+n}a_{1n}\tn{Det}(\widetilde{A_{1n}}),$$
em que $\widetilde{A_{ij}}$ é o $(i,j)$-ésimo *menor* de $A$: isto é, a
matriz $(n-1)\times(n-1)$ obtida de $A$ por deletar a $i$-ésima linha e
$j$-ésima coluna de $A$.

A propriedade que a gente precisa do determinante agora é a seguinte:

:::{#thm-}
$\tn{Det}(AB) = \tn{Det}(A) \tn{Det}(B)$ para quaisquer matrizes
$n\times n$ $A$ e $B$.
:::

A prova deste resultado não é tão fácil com as ferramentas que a gente
tem. Vale a pena ver uma prova dele em algum momento.

:::{#cor-}
Sejam $A,B$ matrizes semelhantes. Então
$$\boxed{\tn{Det}(A) = \tn{Det}(B).}$$
:::

:::{.proof}

$$\begin{aligned}
  \tn{Det}(A) & = \tn{Det}(P^{-1}BP) \\
      & = \tn{Det}(P^{-1})\cdot \tn{Det}(B)\cdot \tn{Det}(P) \\
      & = \tn{Det}(P^{-1})\cdot \tn{Det}(P)\cdot \tn{Det}(B) \\
      & = \tn{Det}(P^{-1}PB) \\
      & = \tn{Det}(B).
\end{aligned}$$ ◻
:::

:::{#exm-}
Do exemplo anterior, as matrizes $$A = \begin{pmatrix}
4 & 2 & 3 \\ -1 & 5 & 3 \\ 1 & 1 & -2 
\end{pmatrix}\quad,\quad B = \begin{pmatrix}
-3 & 8 & 0 \\ -2 & 4 & -4 \\ 4 & -3 & 6 
\end{pmatrix}$$ são semelhantes. Vamos confirmar que os determinantes
são iguais: $$\begin{aligned}
  \tn{Det}(A) & = 4\,\tn{Det}\begin{pmatrix}
  5 & 3 \\ 1 & -2
  \end{pmatrix} - 2\,\tn{Det}\begin{pmatrix}
  -1 & 3 \\ 1 & -2
  \end{pmatrix} + 3\,\tn{Det}\begin{pmatrix}
  -1 & 5 \\ 1 & 1
  \end{pmatrix} \\
  & = 4(-13) - 2(-1) + 3(-6) \\
  & = \ul{\ul{-68}}.
\end{aligned}$$ $$\begin{aligned}
  \tn{Det}(B) & = -3\,\tn{Det}\begin{pmatrix}
  4 & -4 \\ -3 & 6
  \end{pmatrix} - 8\,\tn{Det}\begin{pmatrix}
  -2 & -4 \\ 4 & 6
  \end{pmatrix} + 0\,\tn{Det}\begin{pmatrix}
  -2 & 4 \\ 4 & -3
  \end{pmatrix} \\
  & = -3(12) - 8(4) \\
  & = \ul{\ul{-68}}.\qquad \checkmark
\end{aligned}$$
:::
