---
title: "Diagonalização"
number-sections: true
lang: pt-BR
--- 


# Diagonalização {#diagonalização .unnumbered}

Diagonalização de uma TL $T:V\to V$ é o processo de achar uma base de
$V$ com respeito a qual $T$ é muito fácil entender. As noções de
autovalor, autovetor e autoespaço vão ser fundamentais. Antes de definir
essas coisas, vamos colocar mais um item em nossa lista de invariantes
de matrizes semelhantes. Esta vez, o invariante vai ser um polinômio:

:::{#def-}
Seja $A$ uma matriz $n\times n$. O polinômio
$$p_{A}(t) = {\rm Det}(A- tI)$$ é chamado de *polinômio característico*
de $A$.
:::

:::{#def-}
Seja $f$ um polinômio sobre $\R$.

-   Diremos que $\alpha \in \R$ é uma *raiz* de $f$ se $f(\alpha) = 0;$

-   Se $\alpha$ é uma raiz de $f$, a *multiplicidade* de $\alpha$ como
    raiz de $f$ é o maior inteiro positivo $r$ tal que $(x-\alpha)^r$
    divide $f$.
:::

:::{#exm-}
Seja $$A = \begin{pmatrix}
    4 & 2 & 0 \\ 
    -1& 1& 0 \\
    0 & 1 & 1 
    \end{pmatrix}.$$ Vamos calcular o polinômio caraterístico de $A$:

\begin{aligned}
    p_A(t) & = {\rm Det}(A-tI) \\ 
    & = \tn{Det}\begin{pmatrix}
    4-t & 2 & 0 \\ 
    -1& 1-t & 0 \\
    0& 1 & 1-t 
    \end{pmatrix} \\
    & = (1-t) \tn{Det}\begin{pmatrix}
    4-t & 2  \\ 
    -1& 1-t
    \end{pmatrix} \\
    & = (1-t)((4-t)(1-t)+2)\\
    &= (1-t)(t^2 - 5t+ 6) \\
    & = (1-t)(2-t)(3-t).
\end{aligned} 
Temos que $1, 2$ e $3$ são as raízes do polinômio
caraterístico de $A$, todas com multiplicidade $1$.
:::

:::{#prp-}
Sejam $A$ e $B$ matrizes semelhantes. Os polinômios característicos de
$A$ e $B$ são iguais.
:::

:::{.proof}

$B = P^{-1}AP$. Portanto $$\begin{array}{ccc}
p_B(t) & = & {\rm Det}(B - t I) \\
&= & {\rm Det}(P^{-1}AP - t I) \\
&= & {\rm Det}(P^{-1}AP - t P^{-1}P)\\
&= & {\rm Det}(P^{-1}(A-t I)P) \\
&= & {\rm Det}(P^{-1}){\rm Det}(A-t I){\rm Det}(P) \\
& = & {\rm Det}(A - t I) \\
& = & p_A(t).
\end{array}$$ ◻
:::

Já que matrizes semelhantes representam a mesma TL $T:V\to V$ com
respeito a bases diferentes, esta proposição diz que podemos definir o
polinômio caraterístico de uma TL:

:::{#def-}
Seja $T:V \rightarrow V$ um operador linear (isto é, endomorfismo) sobre
um espaço de dimensão finita $V$ com base $B$.

-   O *determinante* de $T$ é
    $${\rm Det}(T) := {\rm Det}([T]^{B}_{B}).$$

-   O *polinômio característico* de $T$ é
    $$p_{T}(t) = {\rm Det}(T- tI) = \tn{Det}([T]_B^B - tI).$$
:::

Observe que a definição *não depende* da escolha de base, pois
determinantes e polinômios característicos são preservados por
semelhança.

:::{#exm-}
Seja $T: \mathbb{R}^3 \rightarrow \mathbb{R}^3$ o endomorfismo definido
por $T(x,y,z) = (4x+2y,y-x,y+z)$. A matriz de $T$ com respeito à base
canônica $B$ de $\R^3$ é $$[T]^{B}_{B} = \begin{pmatrix}
    4 & 2 & 0 \\ 
    -1& 1& 0 \\
    0 & 1 & 1 
    \end{pmatrix}.$$ Podemos calcular que
${\rm Det}(T) = \tn{Det}([T]_B^B) = 6$. A matriz $[T]_B^B$ é a matriz
$A$ do exemplo anterior, logo $$p_T(t) = p_A(t) = (1-t)(2-t)(3-t).$$
:::

Chegamos para umas definições importantes:

:::{#def-}
Seja $T:V \rightarrow V$ um endomorfismo do espaço vetorial de dimensão
finita $V$. Então:

-   Diremos que $\lambda \in \R$ é um *autovalor* de $T$ se existir
    $\ul{v} \in V\backslash\{\ul{0}\}$ tal que
    $T(\ul{v}) = \lambda \ul{v}$,

-   Se $\lambda$ é um autovalor de $T$, um vetor $\ul{v}\neq \ul{0}$ tal
    que $T(\ul{v}) = \lambda \ul{v}$ se chama de *autovetor* de $T$
    associado a $\lambda$.
:::

[Observação]{.underline}: Se $\lambda$ é um autovalor de $T$, então
$T(\ul{0}) = \ul{0} = \lambda\ul{0}$, mas $\ul{0}$ não é autovetor, pois
autovetores são *não nulos*!

:::{#exm-}
Seja $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ a transformação linear
tal que $T(x,y) = (15x,3y)$. Temos que $T(1,0) = 15(1,0)$ e
$T(0,1)=3(0,1)$. Portanto $15$ e $3$ são autovalores de $T$ e $(1,0)$ e
$(0,1)$ são autovetores associados a $15$ e $3$, respectivamente.
:::

O próximo resultado vai nos dar uma condição para encontrarmos
autovalores de uma transformação linear $T$.

:::{#prp-}
Seja $T: V \rightarrow V$ um endomorfismo linear sobre um espaço de
dimensão finita. Um escalar $\alpha \in \R$ é autovalor de $T$ se, e
somente se, $\alpha$ é raiz do polinômio característico de $T$, ou seja,
se $$p_T(\alpha) = {\rm Det}(T-\alpha I) = 0.$$
:::

:::{.proof}

nulo, $\ul{v}$, tal que $T(\ul{v}) = \alpha \ul{v}$, mas isso é a mesma
coisa de dizer que o sistema $(T-\alpha I)X = \ul{0}$ possui solução não
trivial $\ul{v}$, logo ${\rm Det}(T-\alpha I)= 0$.

Supondo que $\alpha$ é raiz do polinômio caraterístico, então
${\rm Det(}T-\alpha I)= 0$, ou seja, existe $\ul{v}$ não-nulo tal que
$(T-\alpha I)\ul{v} = \ul{0}$, então $T(\ul{v}) = \alpha \ul{v}$,
mostrando que $\alpha$ é um autovalor de $T$. ◻
:::

:::{#exm-}
No exemplo de $T:\R^3\to \R^3$ anterior, os autovalores de $T$ são
exatamente os números $1,2$ e $3$.
:::

:::{#def-}
Dado um autovalor $\lambda$ de $T:V\to V$, o conjunto
$$S_{\lambda} = \{\ul{v} \in V : T(\ul{v}) = \lambda \ul{v}\}$$ é o
*autoespaço de $T$ associado a $\lambda$*.
:::

O nome faz sentido, pois $S_\lambda$ é de fato um subespaço de $V$:

:::{#prp-}
Seja $\lambda \in \R$ um autovalor de $T:V \rightarrow V$. Então
$S_{\lambda} = {\rm Ker}(T-\lambda I)$. Em particular, o autoespaço
$S_\lambda$ é sempre um subespaço de $V$.
:::

:::{.proof}

$$\begin{array}{ccc}
    \ul{x} \in S_{\lambda} & \Longleftrightarrow & T(\ul{x}) = \lambda \ul{x} \\
     &\Longleftrightarrow & (T-\lambda I)\ul{x} = \ul{0} \\
     &\Longleftrightarrow & \ul{x} \in {\rm Ker}(T-\lambda I).
\end{array}$$ Segue que $S_\lambda$ é subespaço de $V$, pois o núcleo de
uma TL sempre o é. ◻
:::

Observe que os elementos de $S_\lambda$ são exatamente os autovetores
associados a $\lambda$, mais o vetor $\ul{0}$.

:::{#exm-}
Voltando ao nosso exemplo $T(x,y,z) = (4x+2y,-x+y,y+z)$. Temos que $1,2$
e $3$ são os autovalores de $T$. Vamos calcular os autoespaços
$S_1, S_2$ e $S_3$.

-   \begin{aligned}
                T(x,y,z) = 1(x,y,z) & \Longleftrightarrow (4x+2y,-x+y,y+z) = (x,y,z) \\
                & \Longleftrightarrow (3x+2y,-x,y) = (0,0,0) \\
                & \Longleftrightarrow x=y=0,
            
    \end{aligned} portanto
    $S_1 = \{ (x,y.z) \in \mathbb{R}^3\,|\, x=y=0 \} = \{ (0,0,z) \in \mathbb{R}^3 : z \in \mathbb{R} \} = [(0,0,1)].$

-   \begin{aligned}
                T(x,y,z) = 2(x,y,z) & \Longleftrightarrow (4x+2y,-x+y,y+z) = (2x,2y,2z) \\
                & \Longleftrightarrow (2x+2y,-x-y,y-z) = (0,0,0) \\
                & \Longleftrightarrow x=-y \ {\rm e } \ y=z,
            
    \end{aligned} portanto
    $S_2 = \{ (-y,y,y) \,|\, y\in \R \} = [(-1,1,1)].$

-   Contas similares dão

    $S_3 = [(-2,1,1/2)]$ \[Exercício: confirme!\]
:::

:::{#exr-}
Seja $\mathcal{P}_2$ o subespaço com base
$\{1,x,x^2\}$ de $\R[x]$. Seja
$T: \mathcal{P}_2 \rightarrow \mathcal{P}_2$ definida por
$T(f(x)) = f(x) + (3x + 2)f'(x)$. Confime que $T$ é TL. Encontre os
autovalores de $T$ e os autoespaços associados.
:::

:::{#exr-}
Seja $T:\R^3\to \R^3$ a TL definida por
$$T(x,y,z) = (x-y-z\,,\,3y+2z\,,\, -y).$$ Encontre os autovalores de $T$
e os autoespaços associados. Observe que um autoespaço pode ter dimensão
maior do que $1$!
:::

:::{#prp-}
Seja $T:V \rightarrow V$ um operador linear.

1.  Para cada autovalor $\lambda$, o autoespaço associado a $\lambda$ é
    $T$-invariante, isto é, $T(S_{\lambda}) \subseteq S_{\lambda}$.

2.  Se $\alpha$ e $\beta$ são dois autovalores distintos, então
    $S_{\alpha}\cap S_{\beta} = \{\ul{0}\}$.
:::

:::{.proof}


1.  Se $\ul{v} \in S_{\lambda}$, então
    $T(\ul{v}) = \lambda \ul{v} \in S_{\lambda}$, já que $S_{\lambda}$ é
    um subespaço.

2.  Se $\ul{v} \in S_{\alpha} \cap S_{\beta}$, então
    $\alpha \ul{v} = T(\ul{v}) = \beta \ul{v}$, portanto
    $(\beta - \alpha)\ul{v} = 0$. Como $\alpha$ e $\beta$ são distintos,
    concluímos que $\ul{v}=0$.

 ◻
:::

:::{#prp-}
Sejam $T:V \rightarrow V$ um operador linear sobre um espaço de dimensão
finita e $\lambda_1,\ldots,\lambda_m$ autovalores distintos de $T$. Se
$\{ \ul{v^i_1},\ldots,\ul{v^i_{k_i}} \}$ é um conjunto LI de autovetores
associados a $\lambda_i$, então
$$X = \{ \ul{v^1_1},\ldots\ul{v^1_{k_1}},\ul{v^2_{1}},\ldots,\ul{v^2_{k_2}}, \ldots ,  \ul{v^m_1},\ldots,\ul{v^m_{k_m}} \}$$
é um conjunto LI.
:::

:::{.proof}

$$X = \{ \ul{v^1_1},\ldots,\ul{v^1_{k_1}}\}$$ é LI por hipótese.

Assuma que o resultado seja válido para $m-1$, ou seja, que
$$\{ \underbrace{\ul{v^1_1},\ldots\ul{v^1_{k_1}},\ul{v^2_{1}},\ldots,\ul{v^2_{k_2}}, \ldots }_{\hbox{esta parte é LI}},  \ul{v^m_1},\ldots,\ul{v^m_{k_m}} \}$$

Seja
$$a^1_1\ul{v^1_1} + ... + a^1_{k_1}\ul{v^1_{k_1}} + \cdots + a^m_1\ul{v^m_1}+\cdots + a^m_{k_m}\ul{v^m_{k_m}} = \ul{0}.\qquad\qquad\qquad (*)$$
Queremos mostrar que cada $a_i^j$ é $0$. Aplicando $T$ pra expressão
$(*)$ acima e usando que $T(\ul{v_i^j}) = \lambda_j \ul{v_i^j}$,
obtemos:
$$\lambda_1a^1_1\ul{v^1_1} + ... + \lambda_1a^1_{k_1}\ul{v^1_{k_1}} + \cdots + \lambda_ma^m_1\ul{v^m_1}+\cdots + \lambda_ma^m_{k_m}\ul{v^m_{k_m}} = \ul{0}.$$
Mas também podemos simplesmente multiplicar a expressão $(*)$ pelo
número $\lambda_m$, obtendo:
$$\lambda_ma^1_1\ul{v^1_1} + ... + \lambda_ma^1_{k_1}\ul{v^1_{k_1}} + \cdots + \lambda_ma^m_1\ul{v^m_1}+\cdots + \lambda_ma^m_{k_m}\ul{v^m_{k_m}} = \ul{0}.$$
Subtraindo a primeira da segunda, obtemos
$$(\lambda_m-\lambda_1)a^1_1\ul{v^1_1} + ... + (\lambda_m - \lambda_1)a^1_{k_1}\ul{v^1_{k_1}} + \cdots + 0a^m_1\ul{v^m_1}+\cdots + 0a^m_{k_m}\ul{v^m_{k_m}} = \ul{0}.$$
Já que esta expressão não envolve os vetores
$\ul{v^m_1},\ldots,\ul{v^m_{k_m}}$, temos por indução que cada
$(\lambda_m-\lambda_j)a_i^j = 0$. Já que
$(\lambda_m - \lambda_j)\neq 0$, obtemos que cada $a_i^j = 0$. Então
nossa expressão original $(*)$ se torna
$$a^m_1\ul{v^m_1}+\cdots + a^m_{k_m}\ul{v^m_{k_m}} = \ul{0},$$ mostrando
que cada $a^m_j = 0$ também, pois o conjunto
$\{ \ul{v^i_1},\ldots,\ul{v^i_{k_i}} \}$ é LI por hipótese. ◻
:::

:::{#def-}
-   Diremos que a matriz $A$ é *diagonalizável* se ela é semelhante a
    uma matriz diagonal. Isto é, se existirem matrizes $D$ e $P$ com $D$
    diagonal e $P$ invertível, tais que $A = P^{-1}DP$.

-   Diremos que um endomorfismo $T:V\rightarrow V$ sobre um espaço de
    dimensão finita é diagonalizável, se existir uma base $B$ de $V$ tal
    que $[T]^{B}_{B}$ é diagonal.
:::

:::{#exm-}
Se $A$ é uma matriz diagonal, então $A = I^{-1}AI$, logo $A$ é
diagonalizável.
:::

:::{#exm-}
Seja $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ definidada por
$T(x,y) = (15x,3y)$. A matriz de $T$ com respeito à base canônica
$B = \{(1,0), (0,1)\}$ é $$[T]^{B}_{B} = \begin{pmatrix}
            15 & 0 \\ 
        0& 3
    \end{pmatrix}$$ logo $T$ é diagonalizável.
:::

:::{#prp-}
Sejam $T:V \rightarrow V$ um operador linear sobre um espaço de dimensão
finita e $B$ uma base de $V$. O operador $T$ é diagonalizável se, e
somente se, $[T]^{B}_{B}$ é uma matriz diagonalizável.
:::

:::{.proof}

respeito a qual a matriz $D = [T]^{C}_{C}$ é diagonal. Mas
$$[T]^{B}_{B} = [I]^{B}_{C}[T]^{C}_{C}[I]^{C}_{B} = 
([I]^{C}_{B})^{-1}D[I]^{C}_{B},$$ portanto a matriz $[T]^{B}_{B}$ é
diagonalizável.

Agora, suponha que a matriz $[T]_B^B$ é diagonalizável. Logo existem
matrizes $D,P$ com $D$ diagonal e $P$ invertível, tais que
$[T]_B^B = P^{-1}DP$. Por exercícios anteriores, para alguma base $C$
temos que $P = [I]_C^B$. Mas já que
$$[T]_B^B = P^{-1}DP = ([I]_C^B)^{-1}D[I]_C^B = [I]_B^CD[I]_C^B,$$ segue
que $D = [T]_C^C$, logo a matriz de $T$ com respeito a $C$ é diagonal, e
portanto $T$ é diagonalizável. ◻
:::

Seja $T: V \rightarrow V$ um endomorfismo diagonalizável e
$C = \{\ul{c_1},\ldots,\ul{c_n}\}$ uma base de $V$ com respeito a qual a
matriz $$[T]_C^C = \begin{pmatrix}
\lambda_1 & 0 & \cdots & 0 \\
0 & \lambda_2 & \cdots & 0 \\
\vdots &&& \\
0 & 0 & \cdots & \lambda_n
\end{pmatrix}$$ é diagonal. Dado $\ul{c_i}\in C$, temos
$$T(\ul{c_i})_C = [T]_C^C\begin{pmatrix}
0 \\ 
\vdots \\
1 \\
\vdots \\
0
\end{pmatrix} =  \begin{pmatrix}
\lambda_1 & 0 & \cdots & 0 \\
0 & \lambda_2 & \cdots & 0 \\
\vdots &&& \\
0 & 0 & \cdots & \lambda_n
\end{pmatrix}\begin{pmatrix}
0 \\ 
\vdots \\
1 \\
\vdots \\
0
\end{pmatrix} = \begin{pmatrix}
0 \\ 
\vdots \\
\lambda_i \\
\vdots \\
0
\end{pmatrix} = \lambda_i\ul{c_i}_C.$$ Ou seja, quando a matriz de $T$
com respeito à base $C$ é diagonal, as entradas da diagonal principal
são *autovalores* de $T$. O $i$-ésimo elemento $\ul{c_i}$ da base $C$ é
um *autovetor* associado ao autovalor $\lambda_i$.

:::{#exm-}
Voltando ao operador linear $T: \mathbb{R}^3 \rightarrow \mathbb{R}^3$
dada por $$T(x,y,z) = (4x+2y,y-x,y+z).$$ Usando a base canônica $B$ de
$\mathbb{R}^3$, vimos que $[T]^{B}_{B} = \begin{pmatrix}
4 & 2 & 0 \\ 
-1& 1& 0 \\
0 & 1 & 1 
\end{pmatrix}$. Os autovalores de $T$ são $1,2$ e $3$ e os autoespaços
associados são
$$S_1 = [(0,0,1)], S_2 = [(-1,1,1)] \hbox{ e }S_3 = [(-2,1,1/2)].$$
Considere a base $C$ de $\R^3$ composta pelas bases dos autoespaços:
$$C = \{(0,0,1)\,,\,(-1,1,1)\,,\,(-2,1,1/2)\}$$ ($C$ é uma base, sendo
LI por uma proposição anterior). A matriz
$$P = [I]_B^C = \begin{pmatrix}
(0,0,1)_B & (-1,1,1)_B & (-2,1,1/2)_B
\end{pmatrix} = \begin{pmatrix}
0 & -1 & -2 \\ 
0& 1& 1 \\
1& 1 & 1/2 
\end{pmatrix}$$ tem inversa $$P^{-1} = [I]_C^B = \begin{pmatrix}
-1/2 & -3/2 & 1 \\ 
1 & 2 & 0 \\
-1 & -1 & 0 
\end{pmatrix}.$$ A matriz de $T$ com respeito à base dos autovetores $C$
(confirme!) é
$$[T]_C^C = [I]_B^C\cdot[T]_B^B\cdot[I]_B^C  = \begin{pmatrix}
1 & 0 & 0 \\ 
0 & 2 & 0 \\
0 & 0 & 3 
\end{pmatrix}.$$
:::

Sempre temos este relacionamento entre diagonalizar matrizes e encontrar
bases de autovetores:

:::{#thm-}
Uma transformação linear $T:V \rightarrow V$ sobre um espaço de dimensão
finita é diagonalizável se, e somente se, o espaço $V$ possui uma base
formada por autovetores.
:::

:::{.proof}

$B = \{\ul{v_1},\ldots,\ul{v_n} \}$ tal que
$$[T]^{B}_{B} = D = \begin{pmatrix}
\lambda_1 & 0 & \cdots & 0 \\
0 & \lambda_2 &  & 0 \\
\vdots &&\ddots& \\
0 & 0 & \cdots & \lambda_n
\end{pmatrix}.$$ Seja $\ul{b_i}$ um vetor da base $B$. Como
$$T(\ul{b_i)}_B = 
\begin{pmatrix}
\lambda_1 & 0 & \cdots & 0 \\
0 & \lambda_2 &  & 0 \\
\vdots &&\ddots& \\
0 & 0 & \cdots & \lambda_n
\end{pmatrix}\begin{pmatrix}
0 \\
\vdots \\
1 \\
\vdots \\
0
\end{pmatrix} = \begin{pmatrix}
0 \\
\vdots \\
\lambda_i \\
\vdots \\
0
\end{pmatrix} = \lambda_i\ul{b_i}_B,$$ segue que
$T(\ul{b_i}) = \lambda_i\ul{b_i}$, ou seja, que $\ul{b_i}$ é um
autovetor de $T$ com autovalor correspondente $\lambda_i$. Logo $B$ é
uma base de $V$ composta de autovetores.

Agora supondo que exista uma base de autovetores
$B = \{ \ul{b_1},\ldots,\ul{b_n}\}$ (com $\ul{b_i}$ associado ao
autovalor $\lambda_i$), temos \begin{aligned}
    T(\ul{b_1}) & = \lambda_1\ul{b_1} + 0\ul{b_2} + \cdots + 0\ul{b_n},\\
T(\ul{b_2}) & = 0\ul{b_1} + \lambda_2\ul{b_2} + \cdots + 0\ul{b_n}, \\
& \vdots \\
T(\ul{b_n}) & =  0\ul{b_1} + 0\ul{b_2} + \cdots + \lambda_n\ul{b_n}
\end{aligned} então a matriz de $T$ com respeito à base $B$ é
$$[T]^{B}_{B} = \begin{pmatrix}
\lambda_1 & 0 & \cdots & 0 \\
0 & \lambda_2 &  & 0 \\
\vdots &&\ddots& \\
0 & 0 & \cdots & \lambda_n
\end{pmatrix}$$ logo $T$ é um operador diagonalizável. ◻
:::

:::{#exm-}
Seja $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ o operador linear dado
por $T(x,y) = (y,0)$. Com respeito à base canônica $B$ de
$\mathbb{R}^2$, $$[T]^{B}_{B} = \begin{pmatrix}
0 & 1 \\ 
0 & 0
\end{pmatrix}.$$ O polinômio caraterístico $p_T(t) = t^2$, logo $0$ é o
único autovalor de $T$ (= raiz de $p_T$) e ele tem multiplicade $2$. O
autoespaço $S_0$ associado a $0$ é
$$S_0 = \tn{Ker}(T - 0I) = \tn{Ker}(T) = \{(x,0)\,|\,x\in \R\},$$ cuja
dimensão é $1$. Segue que não existe uma base de $\R^2$ composta de
autovetores de $T$, então pelo teorema, $T$ *não é* diagonalizável.
:::
